<!DOCTYPE html>
<html>

<head>

<meta charset="utf-8">
<title>ADMM_for_interview</title>


<style type="text/css">
body {
  font-family: Helvetica, arial, sans-serif;
  font-size: 14px;
  line-height: 1.6;
  padding-top: 10px;
  padding-bottom: 10px;
  background-color: white;
  padding: 30px; }

body > *:first-child {
  margin-top: 0 !important; }
body > *:last-child {
  margin-bottom: 0 !important; }

a {
  color: #4183C4; }
a.absent {
  color: #cc0000; }
a.anchor {
  display: block;
  padding-left: 30px;
  margin-left: -30px;
  cursor: pointer;
  position: absolute;
  top: 0;
  left: 0;
  bottom: 0; }

h1, h2, h3, h4, h5, h6 {
  margin: 20px 0 10px;
  padding: 0;
  font-weight: bold;
  -webkit-font-smoothing: antialiased;
  cursor: text;
  position: relative; }

h1:hover a.anchor, h2:hover a.anchor, h3:hover a.anchor, h4:hover a.anchor, h5:hover a.anchor, h6:hover a.anchor {
  background: url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAYAAAAf8/9hAAAAGXRFWHRTb2Z0d2FyZQBBZG9iZSBJbWFnZVJlYWR5ccllPAAAA09pVFh0WE1MOmNvbS5hZG9iZS54bXAAAAAAADw/eHBhY2tldCBiZWdpbj0i77u/IiBpZD0iVzVNME1wQ2VoaUh6cmVTek5UY3prYzlkIj8+IDx4OnhtcG1ldGEgeG1sbnM6eD0iYWRvYmU6bnM6bWV0YS8iIHg6eG1wdGs9IkFkb2JlIFhNUCBDb3JlIDUuMy1jMDExIDY2LjE0NTY2MSwgMjAxMi8wMi8wNi0xNDo1NjoyNyAgICAgICAgIj4gPHJkZjpSREYgeG1sbnM6cmRmPSJodHRwOi8vd3d3LnczLm9yZy8xOTk5LzAyLzIyLXJkZi1zeW50YXgtbnMjIj4gPHJkZjpEZXNjcmlwdGlvbiByZGY6YWJvdXQ9IiIgeG1sbnM6eG1wPSJodHRwOi8vbnMuYWRvYmUuY29tL3hhcC8xLjAvIiB4bWxuczp4bXBNTT0iaHR0cDovL25zLmFkb2JlLmNvbS94YXAvMS4wL21tLyIgeG1sbnM6c3RSZWY9Imh0dHA6Ly9ucy5hZG9iZS5jb20veGFwLzEuMC9zVHlwZS9SZXNvdXJjZVJlZiMiIHhtcDpDcmVhdG9yVG9vbD0iQWRvYmUgUGhvdG9zaG9wIENTNiAoMTMuMCAyMDEyMDMwNS5tLjQxNSAyMDEyLzAzLzA1OjIxOjAwOjAwKSAgKE1hY2ludG9zaCkiIHhtcE1NOkluc3RhbmNlSUQ9InhtcC5paWQ6OUM2NjlDQjI4ODBGMTFFMTg1ODlEODNERDJBRjUwQTQiIHhtcE1NOkRvY3VtZW50SUQ9InhtcC5kaWQ6OUM2NjlDQjM4ODBGMTFFMTg1ODlEODNERDJBRjUwQTQiPiA8eG1wTU06RGVyaXZlZEZyb20gc3RSZWY6aW5zdGFuY2VJRD0ieG1wLmlpZDo5QzY2OUNCMDg4MEYxMUUxODU4OUQ4M0REMkFGNTBBNCIgc3RSZWY6ZG9jdW1lbnRJRD0ieG1wLmRpZDo5QzY2OUNCMTg4MEYxMUUxODU4OUQ4M0REMkFGNTBBNCIvPiA8L3JkZjpEZXNjcmlwdGlvbj4gPC9yZGY6UkRGPiA8L3g6eG1wbWV0YT4gPD94cGFja2V0IGVuZD0iciI/PsQhXeAAAABfSURBVHjaYvz//z8DJYCRUgMYQAbAMBQIAvEqkBQWXI6sHqwHiwG70TTBxGaiWwjCTGgOUgJiF1J8wMRAIUA34B4Q76HUBelAfJYSA0CuMIEaRP8wGIkGMA54bgQIMACAmkXJi0hKJQAAAABJRU5ErkJggg==) no-repeat 10px center;
  text-decoration: none; }

h1 tt, h1 code {
  font-size: inherit; }

h2 tt, h2 code {
  font-size: inherit; }

h3 tt, h3 code {
  font-size: inherit; }

h4 tt, h4 code {
  font-size: inherit; }

h5 tt, h5 code {
  font-size: inherit; }

h6 tt, h6 code {
  font-size: inherit; }

h1 {
  font-size: 28px;
  color: black; }

h2 {
  font-size: 24px;
  border-bottom: 1px solid #cccccc;
  color: black; }

h3 {
  font-size: 18px; }

h4 {
  font-size: 16px; }

h5 {
  font-size: 14px; }

h6 {
  color: #777777;
  font-size: 14px; }

p, blockquote, ul, ol, dl, li, table, pre {
  margin: 15px 0; }

hr {
  background: transparent url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAYAAAAECAYAAACtBE5DAAAAGXRFWHRTb2Z0d2FyZQBBZG9iZSBJbWFnZVJlYWR5ccllPAAAAyJpVFh0WE1MOmNvbS5hZG9iZS54bXAAAAAAADw/eHBhY2tldCBiZWdpbj0i77u/IiBpZD0iVzVNME1wQ2VoaUh6cmVTek5UY3prYzlkIj8+IDx4OnhtcG1ldGEgeG1sbnM6eD0iYWRvYmU6bnM6bWV0YS8iIHg6eG1wdGs9IkFkb2JlIFhNUCBDb3JlIDUuMC1jMDYwIDYxLjEzNDc3NywgMjAxMC8wMi8xMi0xNzozMjowMCAgICAgICAgIj4gPHJkZjpSREYgeG1sbnM6cmRmPSJodHRwOi8vd3d3LnczLm9yZy8xOTk5LzAyLzIyLXJkZi1zeW50YXgtbnMjIj4gPHJkZjpEZXNjcmlwdGlvbiByZGY6YWJvdXQ9IiIgeG1sbnM6eG1wPSJodHRwOi8vbnMuYWRvYmUuY29tL3hhcC8xLjAvIiB4bWxuczp4bXBNTT0iaHR0cDovL25zLmFkb2JlLmNvbS94YXAvMS4wL21tLyIgeG1sbnM6c3RSZWY9Imh0dHA6Ly9ucy5hZG9iZS5jb20veGFwLzEuMC9zVHlwZS9SZXNvdXJjZVJlZiMiIHhtcDpDcmVhdG9yVG9vbD0iQWRvYmUgUGhvdG9zaG9wIENTNSBNYWNpbnRvc2giIHhtcE1NOkluc3RhbmNlSUQ9InhtcC5paWQ6OENDRjNBN0E2NTZBMTFFMEI3QjRBODM4NzJDMjlGNDgiIHhtcE1NOkRvY3VtZW50SUQ9InhtcC5kaWQ6OENDRjNBN0I2NTZBMTFFMEI3QjRBODM4NzJDMjlGNDgiPiA8eG1wTU06RGVyaXZlZEZyb20gc3RSZWY6aW5zdGFuY2VJRD0ieG1wLmlpZDo4Q0NGM0E3ODY1NkExMUUwQjdCNEE4Mzg3MkMyOUY0OCIgc3RSZWY6ZG9jdW1lbnRJRD0ieG1wLmRpZDo4Q0NGM0E3OTY1NkExMUUwQjdCNEE4Mzg3MkMyOUY0OCIvPiA8L3JkZjpEZXNjcmlwdGlvbj4gPC9yZGY6UkRGPiA8L3g6eG1wbWV0YT4gPD94cGFja2V0IGVuZD0iciI/PqqezsUAAAAfSURBVHjaYmRABcYwBiM2QSA4y4hNEKYDQxAEAAIMAHNGAzhkPOlYAAAAAElFTkSuQmCC) repeat-x 0 0;
  border: 0 none;
  color: #cccccc;
  height: 4px;
  padding: 0;
}

body > h2:first-child {
  margin-top: 0;
  padding-top: 0; }
body > h1:first-child {
  margin-top: 0;
  padding-top: 0; }
  body > h1:first-child + h2 {
    margin-top: 0;
    padding-top: 0; }
body > h3:first-child, body > h4:first-child, body > h5:first-child, body > h6:first-child {
  margin-top: 0;
  padding-top: 0; }

a:first-child h1, a:first-child h2, a:first-child h3, a:first-child h4, a:first-child h5, a:first-child h6 {
  margin-top: 0;
  padding-top: 0; }

h1 p, h2 p, h3 p, h4 p, h5 p, h6 p {
  margin-top: 0; }

li p.first {
  display: inline-block; }
li {
  margin: 0; }
ul, ol {
  padding-left: 30px; }

ul :first-child, ol :first-child {
  margin-top: 0; }

dl {
  padding: 0; }
  dl dt {
    font-size: 14px;
    font-weight: bold;
    font-style: italic;
    padding: 0;
    margin: 15px 0 5px; }
    dl dt:first-child {
      padding: 0; }
    dl dt > :first-child {
      margin-top: 0; }
    dl dt > :last-child {
      margin-bottom: 0; }
  dl dd {
    margin: 0 0 15px;
    padding: 0 15px; }
    dl dd > :first-child {
      margin-top: 0; }
    dl dd > :last-child {
      margin-bottom: 0; }

blockquote {
  border-left: 4px solid #dddddd;
  padding: 0 15px;
  color: #777777; }
  blockquote > :first-child {
    margin-top: 0; }
  blockquote > :last-child {
    margin-bottom: 0; }

table {
  padding: 0;border-collapse: collapse; }
  table tr {
    border-top: 1px solid #cccccc;
    background-color: white;
    margin: 0;
    padding: 0; }
    table tr:nth-child(2n) {
      background-color: #f8f8f8; }
    table tr th {
      font-weight: bold;
      border: 1px solid #cccccc;
      margin: 0;
      padding: 6px 13px; }
    table tr td {
      border: 1px solid #cccccc;
      margin: 0;
      padding: 6px 13px; }
    table tr th :first-child, table tr td :first-child {
      margin-top: 0; }
    table tr th :last-child, table tr td :last-child {
      margin-bottom: 0; }

img {
  max-width: 100%; }

span.frame {
  display: block;
  overflow: hidden; }
  span.frame > span {
    border: 1px solid #dddddd;
    display: block;
    float: left;
    overflow: hidden;
    margin: 13px 0 0;
    padding: 7px;
    width: auto; }
  span.frame span img {
    display: block;
    float: left; }
  span.frame span span {
    clear: both;
    color: #333333;
    display: block;
    padding: 5px 0 0; }
span.align-center {
  display: block;
  overflow: hidden;
  clear: both; }
  span.align-center > span {
    display: block;
    overflow: hidden;
    margin: 13px auto 0;
    text-align: center; }
  span.align-center span img {
    margin: 0 auto;
    text-align: center; }
span.align-right {
  display: block;
  overflow: hidden;
  clear: both; }
  span.align-right > span {
    display: block;
    overflow: hidden;
    margin: 13px 0 0;
    text-align: right; }
  span.align-right span img {
    margin: 0;
    text-align: right; }
span.float-left {
  display: block;
  margin-right: 13px;
  overflow: hidden;
  float: left; }
  span.float-left span {
    margin: 13px 0 0; }
span.float-right {
  display: block;
  margin-left: 13px;
  overflow: hidden;
  float: right; }
  span.float-right > span {
    display: block;
    overflow: hidden;
    margin: 13px auto 0;
    text-align: right; }

code, tt {
  margin: 0 2px;
  padding: 0 5px;
  white-space: nowrap;
  border: 1px solid #eaeaea;
  background-color: #f8f8f8;
  border-radius: 3px; }

pre code {
  margin: 0;
  padding: 0;
  white-space: pre;
  border: none;
  background: transparent; }

.highlight pre {
  background-color: #f8f8f8;
  border: 1px solid #cccccc;
  font-size: 13px;
  line-height: 19px;
  overflow: auto;
  padding: 6px 10px;
  border-radius: 3px; }

pre {
  background-color: #f8f8f8;
  border: 1px solid #cccccc;
  font-size: 13px;
  line-height: 19px;
  overflow: auto;
  padding: 6px 10px;
  border-radius: 3px; }
  pre code, pre tt {
    background-color: transparent;
    border: none; }

sup {
    font-size: 0.83em;
    vertical-align: super;
    line-height: 0;
}
* {
	-webkit-print-color-adjust: exact;
}
@media screen and (min-width: 914px) {
    body {
        width: 854px;
        margin:0 auto;
    }
}
@media print {
	table, pre {
		page-break-inside: avoid;
	}
	pre {
		word-wrap: break-word;
	}
}
</style>

<style type="text/css">
/**
 * prism.js default theme for JavaScript, CSS and HTML
 * Based on dabblet (http://dabblet.com)
 * @author Lea Verou
 */

code[class*="language-"],
pre[class*="language-"] {
	color: black;
	background: none;
	text-shadow: 0 1px white;
	font-family: Consolas, Monaco, 'Andale Mono', 'Ubuntu Mono', monospace;
	text-align: left;
	white-space: pre;
	word-spacing: normal;
	word-break: normal;
	word-wrap: normal;
	line-height: 1.5;

	-moz-tab-size: 4;
	-o-tab-size: 4;
	tab-size: 4;

	-webkit-hyphens: none;
	-moz-hyphens: none;
	-ms-hyphens: none;
	hyphens: none;
}

pre[class*="language-"]::-moz-selection, pre[class*="language-"] ::-moz-selection,
code[class*="language-"]::-moz-selection, code[class*="language-"] ::-moz-selection {
	text-shadow: none;
	background: #b3d4fc;
}

pre[class*="language-"]::selection, pre[class*="language-"] ::selection,
code[class*="language-"]::selection, code[class*="language-"] ::selection {
	text-shadow: none;
	background: #b3d4fc;
}

@media print {
	code[class*="language-"],
	pre[class*="language-"] {
		text-shadow: none;
	}
}

/* Code blocks */
pre[class*="language-"] {
	padding: 1em;
	margin: .5em 0;
	overflow: auto;
}

:not(pre) > code[class*="language-"],
pre[class*="language-"] {
	background: #f5f2f0;
}

/* Inline code */
:not(pre) > code[class*="language-"] {
	padding: .1em;
	border-radius: .3em;
	white-space: normal;
}

.token.comment,
.token.prolog,
.token.doctype,
.token.cdata {
	color: slategray;
}

.token.punctuation {
	color: #999;
}

.namespace {
	opacity: .7;
}

.token.property,
.token.tag,
.token.boolean,
.token.number,
.token.constant,
.token.symbol,
.token.deleted {
	color: #905;
}

.token.selector,
.token.attr-name,
.token.string,
.token.char,
.token.builtin,
.token.inserted {
	color: #690;
}

.token.operator,
.token.entity,
.token.url,
.language-css .token.string,
.style .token.string {
	color: #a67f59;
	background: hsla(0, 0%, 100%, .5);
}

.token.atrule,
.token.attr-value,
.token.keyword {
	color: #07a;
}

.token.function {
	color: #DD4A68;
}

.token.regex,
.token.important,
.token.variable {
	color: #e90;
}

.token.important,
.token.bold {
	font-weight: bold;
}
.token.italic {
	font-style: italic;
}

.token.entity {
	cursor: help;
}
</style>

<style type="text/css">
pre.line-numbers {
	position: relative;
	padding-left: 3.8em;
	counter-reset: linenumber;
}

pre.line-numbers > code {
	position: relative;
}

.line-numbers .line-numbers-rows {
	position: absolute;
	pointer-events: none;
	top: 0;
	font-size: 100%;
	left: -3.8em;
	width: 3em; /* works for line-numbers below 1000 lines */
	letter-spacing: -1px;
	border-right: 1px solid #999;

	-webkit-user-select: none;
	-moz-user-select: none;
	-ms-user-select: none;
	user-select: none;

}

	.line-numbers-rows > span {
		pointer-events: none;
		display: block;
		counter-increment: linenumber;
	}

		.line-numbers-rows > span:before {
			content: counter(linenumber);
			color: #999;
			display: block;
			padding-right: 0.8em;
			text-align: right;
		}
</style>


</head>

<body>

<h2 id="toc_0">ADMM for interview</h2>

<ul>
<li>author: <a href="mailto:zhouyongsdzh@foxmail.com">zhouyongsdzh@foxmail.com</a></li>
<li>date: 20160404</li>
</ul>

<p><br></p>

<h3 id="toc_1">4. ADMM算法框架</h3>

<hr>

<p><br></p>

<h4 id="toc_2">4.1. ADMM简介</h4>

<hr>

<p>对于一个有约束条件的优化问题来说，通常的求解方式是构造拉格朗日函数，然后利用<strong>交替优化</strong>的思路，不断地迭代参数和对偶变量（乘子）参数updated表达式，使得两者同时达到optimal。这就是对偶上升法（Dual Ascent）求解的核心思想。</p>

<p>对偶上升法有一个优点就是<strong>如果目标函数是可分的，它可以在分布式环境下求解</strong>。但是它也有一个很大的缺点就是<strong>目标函数必须是强凸函数</strong>。这个对于一般的凸函数，如果用对偶上升法求解参数，并不能得到最优解。</p>

<p>为了解决对偶上升法的缺点，在原有的拉格朗日函数基础上加上<strong>惩罚函数项</strong>（二次项），目标就是为了解决Dual Ascent方法对目标函数要求过于严格的问题。这种优化方法称为<strong>增广拉格朗日乘子法（Argument Lagrange Multipliers）</strong>。</p>

<blockquote>
<p>通过引入惩罚函数项（二次项），放松对于\(f(x)\)严格凸的假设和其他一些条件，同时使得算法更加稳健。</p>
</blockquote>

<p>虽然增广拉格朗日法放松了对目标函数的限制，但也破坏了dual ascent方法通过<strong>分解参数来并行计算</strong>的优势。因为二次项计算时写成矩阵形式，无法用之前的分块形式。</p>

<blockquote>
<p><strong>当\(f\)是separable时，对于Augmented Lagrangians却是not separable的（因为平方项写成矩阵形式无法用之前那种分块形式）</strong></p>
</blockquote>

<p>为了利用<strong>dual ascent带来的目标函数可分解与增广拉格朗日法带来的更一般化的参数求解</strong>性质。人们提出了ADMM算法。ADMM的思想就是说把原变量、目标函数进行拆分，拆分成不同的变量。形式如下：</p>

<p>$$
\begin{align}
&amp; min \quad f(x) + g(z)  \
&amp; s.t \quad Ax + B z = C
\end{align}  \qquad (2.1)
$$</p>

<p>从上面形式确实可以看出，ADMM的思想就是想把primal变量、目标函数拆分，但是不再像dual ascent方法那样，将拆分开的\(x_i\)都看做是\(\mathbf{x}\)的一部分，后面融合的时候还需要融合在一起。而是最先开始就将拆开的变量分别看做是不同的变量\(x\)和\(z\)，约束条件也如此处理。这样的好处就是后面不需要一起融合\(x\)和\(z\)，保证了前面优化过程的可分解性。</p>

<p>ADMM（Alternating Direction Method of Multipliers，交替方向乘子法）算法框架 之所以能在分布式环境用于大规模学习任务，概括起来主要有3点：</p>

<ul>
<li><p><strong>目标函数可分</strong>：可用于多个子任务学习</p>

<p>将一个整体的任务划分为多个子任务进行学习，每个子任务在一个计算节点（worker）上计算，多个worker节点与一个master节点通信。</p>

<blockquote>
<p>worker更新局部参数和对偶变量；master更新全局参数。</p>
</blockquote></li>
<li><p><strong>目标函数结构，引入交叉方向</strong></p>

<p>拆分目标函数和原变量，引入交叉方向变量用于局部参数与全局参数的交替优化</p></li>
<li><p><strong>约束条件</strong>：用于保证ADMM形式的优化问题与原优化问题等价。</p></li>
</ul>

<h4 id="toc_3">4.2. ADMM + LR 表达式</h4>

<p>机器学习模型的优化的目标函数很多是<strong>“损失函数项＋正则项”</strong>的形式，如LR模型，符合ADMM算法框架表达。</p>

<p>LR模型损失函数（Log损失，交叉熵损失）：</p>

<p>$$
    \begin{align}
    l \,(y<sup>{(i)},</sup> h<u>w(x<sup>{(i)}))</sup> &amp; = - \log \, L(w) \
    &amp; = - \sum</u>{i=1}<sup>{m}</sup> \left( y<sup>{(i)}</sup> \cdot \log (h<u>{w}(x<sup>{(i)}))</sup> + (1-y<sup>{(i)})</sup> \cdot \log(1- h</u>{w}(x<sup>{(i)}))</sup> \right)
    \end{align} \qquad (1)
    $$</p>

<p>改写为ADMM形式（加上\(\text{L}_1正则化项\)）：</p>

<p>$$
\begin{align}
&amp; \min<u>{\theta, w</u>1, \cdots, w<u>T} \quad \sum</u>{t=1}<sup>{T}</sup> \frac{1}{m<u>t} \sum</u>{i=1}<sup>{m_t}</sup> l \,(y<sup>{(i)},</sup> h<u>{w</u>t}(x<sup>{(i)}))</sup> + \lambda {\Vert \theta \Vert}<u>1 \
&amp; \quad s.t.    \qquad w</u>t = \theta \;(t=1,\cdots,T)
\end{align}     \qquad(2)
$$</p>

<blockquote>
<p>ADMM算法待优化的目标函数结构形式为：\(f(x) + g(x)\)。目的是区分参数为局部参数和全局参数。局部参数在多个节点进行计算，通过全局参数实现数据信息共享（全局参数信息在多机器之间通过allreduce/broadcast通信来体现）。</p>

<p>约束条件\(w_t = \theta\) 保证了ADMM形式的目标函数与LR损失函数等价。</p>
</blockquote>

<p>增广拉格朗日函数（拉格朗日乘子项 + 损失函数项）为：</p>

<p>$$
\sum<u>{t=1}<sup>{T}</sup> \frac{1}{m</u>t} \, l \left(\mathbf{Y}<u>t, h</u>{w<u>t}(\mathbf{X}</u>t)  \right) + \lambda {\Vert \theta \Vert}<u>1 + \sum</u>{t=1}<sup>{T}</sup> \alpha<u>{t}<sup>T</sup> (w</u>t - \theta) + \frac{\rho}{2} \sum<u>{t=1}<sup>{T}</sup> {\Vert w</u>t - \theta \Vert}_2<sup>2</sup> \qquad(3)
$$</p>

<p>迭代步骤为：</p>

<ul>
<li>\(w\)更新（worker节点）：</li>
</ul>

<p>$$
\begin{align}
w<u>t &amp; \longleftarrow \text{arg} \min</u>w \frac{1}{m<u>t} \, l \left(\mathbf{Y}</u>t, h<u>{w</u>t}(\mathbf{X}<u>t) \right) + \alpha</u>t<sup>T</sup> w<u>t + \frac{\rho}{2} {\Vert w</u>t - \theta \Vert}<u>2<sup>2</sup> \
\Longrightarrow  w</u>t &amp; \longleftarrow \text{arg} \min<u>w \frac{1}{m</u>t} \, l \left(\mathbf{Y}<u>t, h</u>{w<u>t}(\mathbf{X}</u>t) \right) + \frac{\rho}{2} {\left \Vert w<u>t - \theta + \frac{1}{\rho} \alpha</u>t \right \Vert}_2<sup>2</sup>
\end{align}
$$</p>

<ul>
<li>\(\alpha\)更新（worker节点）</li>
</ul>

<p>$$
\alpha<u>t \longleftarrow \alpha</u>t + \rho(w_t - \theta)
$$</p>

<ul>
<li><p>\(\theta\)更新（master节点）</p>

<p>$$
\begin{align}
\theta &amp;\longleftarrow \arg \min<u>{\theta} \lambda {\Vert \theta \Vert}</u>1 -\sum<u>{t=1}<sup>{T}</sup> \alpha<sup>T</sup> \theta + \frac{\rho}{2} \sum</u>{t=1}<sup>{T}</sup> {\Vert w<u>t -\theta \Vert}</u>2<sup>2</sup> \
\Longrightarrow \theta &amp;\longleftarrow 
\begin{cases}
    \frac{1}{T} \left(\sum<u>t (w</u>t + \frac{\alpha<u>t}{\rho}) - \frac{\lambda}{\rho} \right), &amp; \quad \text{if } \sum</u>t (w<u>t + \frac{\alpha</u>t}{\rho}) \gt \frac{\lambda}{\rho} \
    \frac{1}{T} \left(\sum<u>t (w</u>t + \frac{\alpha<u>t}{\rho}) + \frac{\lambda}{\rho} \right), &amp; \quad \text{if } \sum</u>t (w<u>t + \frac{\alpha</u>t}{\rho}) \lt -\frac{\lambda}{\rho} \
    \quad 0, &amp;\quad \text{if  otherwise} .
\end{cases}
\end{align}
$$</p>

<blockquote>
<p>软阈值 soft-thresholding.</p>
</blockquote></li>
</ul>

<h4 id="toc_4">4.3. 局部参数学习算法－FTRL-Proximal</h4>

<h5 id="toc_5">FTRL-Proximal由来</h5>

<ul>
<li><p>在线梯度下降（Online Gradient Descent，OGD）</p>

<p>可以有非常好的预估准确性，并且占用较少的资源。但是它不能得到有效的稀疏模型（非零参数），就是说添加L1惩罚项也不能产生严格意义上的稀疏解（参数为0）。</p></li>
<li><p>Truncated Gradient and FOBOS      </p>

<p>参数\(w_j\)设定阈值，当参数小雨阈值时置为0，如此得到稀疏解。</p></li>
<li><p>正则化对偶平均（Regularized Dual Averaging，RDA）</p>

<p>RDA可以得到稀疏解，在预估准确性和模型稀疏性方面优于FOBOS算法。</p></li>
</ul>

<p>有没有既能结合RDA获得模型稀疏性，同时又具备OGD的精度的学习算法呢？答案是肯定的，那就是：<q>Follow The (Proximal) Regularized Leader</q>算法。</p>

<h5 id="toc_6">模型与参数学习</h5>

<p>如果用FTRL-Proximal算法训练LR模型：</p>

<ul>
<li><p>首先，预测实例\(\mathbf{x}<sup>{(i)}</sup> \in R<sup>n\)的label（在给定模型参数\(\mathbf{w}<sup>{(i)}\)）。公式为\(p<sup>{(i)}</sup></sup></sup> = \sigma(\mathbf{w}<sup>{(i)}</sup> \cdot \mathbf{x}<sup>{(i)}),</sup> \; \sigma(a) = \frac{1}{1 + \exp(-a)}\).</p></li>
<li><p>然后，观测标签\(y<sup>{(i)}</sup> \in {0,1}\)，LR模型的损失函数（Logistic Loss）为：</p>

<p>$$
\mathcal{l} \; (w<sup>{(i)})</sup> = -y<sup>{(i)}</sup> \log p<sup>{(i)}</sup> - (1 - y<sup>{(i)})</sup> \log (1- p<sup>{(i)})</sup> \qquad (1)
$$</p>

<p>梯度方向：</p>

<p>$$
\frac{\partial l \;(w)} {\partial w} = (\sigma(w \cdot x<sup>{(i)})</sup> - y<sup>{(i)})</sup> = (p<sup>{(i)}</sup> - y<sup>{(i)})</sup> \cdot \mathbf{x}<sup>{(i)}</sup> \qquad(2)
$$</p></li>
<li><p>OGD算法迭代公式：</p>

<p>$$
w<u>{i+1} = w</u>i - \eta<u>i \mathbf{g}</u>i \qquad(3)
$$</p>

<p>其中\(\eta<u>i\)表示非递增的学习率，如\(\eta</u>i=\frac{1}{\sqrt{i}}\)，\(\mathbf{g}_i\)表示当前梯度值。</p></li>
<li><p>FTRL-Proximal</p>

<p>$$
\mathbf{w}<u>{i+1} = \text{arg} \min</u>w \left( \underline{ \sum<u>{s=1}<sup>{i}</sup> \mathbf{g}</u>s} \cdot \mathbf{w} + \frac{1}{2} \sum<u>{s=1}<sup>{i}</sup> \sigma</u>s {\Vert \mathbf{w} - \mathbf{w}<u>s \Vert}</u>2<sup>2</sup> + \lambda<u>1 {\Vert \mathbf{w} \Vert}</u>1 \right) \qquad(4)
$$</p>

<p>\(\sigma<u>s\)为学习率参数，有\(\sigma</u>{1:i} = \frac{1}{\eta_i}\)。上式等价于：</p>

<p>$$
\left( \sum<u>{s=1}<sup>{i}</sup> \mathbf{g}</u>s  - \sum<u>{s=1}<sup>{i}</sup> \sigma</u>s \mathbf{w}<u>s \right) \cdot \mathbf{w} + \frac{1}{\eta</u>i} {\Vert \mathbf{w} \Vert}<u>2<sup>2</sup> + \lambda</u>1 {\Vert \mathbf{w} \Vert}_1  + (\text{const})  \qquad(5)
$$</p>

<p>如果我们存储\(\mathbf{z}<u>{i-1} = \sum</u>{s=1}<sup>{i-1}</sup> \mathbf{g}<u>s  - \sum</u>{s=1}<sup>{i-1}</sup> \sigma<u>s \mathbf{w}</u>s\)，在第\(i\)轮迭代时，\(\mathbf{z}<u>i = \mathbf{z}</u>{i-1} + \mathbf{g}<u>i + \left(\frac{1}{\eta</u>i} - \frac{1}{\eta<u>{i-1}} \right) \mathbf{w}</u>i\)。求\(\mathbf{w}_{i+1}\)每一维参数的闭式解为：</p>

<p>$$
w<u>{i+1, j} = 
\left {
\begin{array}{ll}
0, &amp; \text{if} \; |z</u>{i,j}| \le \lambda<u>1 \
-\eta</u>i \left(z<u>{i,j} - \text{sgn}(z</u>{i,j}) \lambda_1 \right) &amp; \text{otherwise}.
\end{array}
\right.     \qquad(6)
$$</p>

<p>每一维特征的学习率计算公式（与对应特征维度梯度累加和 &amp;&amp; 梯度平方和相关）：</p>

<p>$$
\eta<u>{i,j} = \frac{\alpha}{\beta + \sqrt{\sum</u>{s=1}<sup>{i}</sup> g<u>{s,j}<sup>2}}</sup> = \frac{1}{\sqrt{n</u>{i+1,j}}}
\qquad(7)
$$</p>

<p>\(n<u>i = \sum</u>{s=1}<sup>{i-1}</sup> g_{s}<sup>2\)表示梯度平方累加和。</sup></p>

<p>FTRL-Proximal存储参数\(\mathbf{z} \in R<sup>n\)在内存。</sup></p></li>
<li><p>FTRL-Proximal 伪代码</p>

<p>\({ \
\quad \text{Per-Coordinate FTRL-Proximal with L}<u>1 \text{ and L}</u>2 \text{ Regularization for Logistic Regression. }  \
\quad \text{// 支持} L<u>1 \text{与} L</u>2  \text{正则项的FTRL-Proximal算法. Per-Coordinate学习率为公式(7). } \
\quad \text{Input: parameters } \alpha, \beta, \lambda<u>1, \lambda</u>2. \qquad //  参数 \alpha, \beta 用于\text{Per-Coordinate}计算学习率 \
\quad (\text{对于任意的}\; j \in {1, &hellip;, d}), 初始化z<u>i = 0 和n</u>i=0. \qquad // 总共d个值. \
\quad \mathbf{\text{for}} \; t=1 \; to \; T; do \
\quad \qquad 接受特征向量\mathbf{x}<u>t \; and 让 I = {i| x</u>i \neq 0 }. \quad //取非0特征index集合. \
\quad \qquad \text{For i} \in I, 计算  \
\quad \qquad\qquad w<u>{t, i} = 
\quad \left {
\quad \begin{array}{ll}
0, &amp; \text{if} \; |z</u>{i,j}| \le \lambda<u>1 \
-\left( \frac{\beta + \sqrt{n</u>i}}{\alpha} + \lambda<u>2 \right)<sup>{-1}</sup> \left(z</u>{i} - \text{sgn}(z<u>{i}) \lambda</u>1 \right) &amp; \text{otherwise}.
\end{array}
\right. \
\quad \qquad 预测 p<u>t = \sigma(\mathbf{x}</u>t \cdot \mathbf{w}) 使用w<u>{t,i}计算，Predict函数。\
\quad \qquad 观测样本 y</u>t \in {0, 1} \qquad //下面更新参数，\text{Update(p, y, x)}函数 \
\quad \qquad \text{for all } \; i \in I; do \
\quad \qquad\qquad g<u>i = (p</u>t - y<u>t) x</u>i    \quad \qquad // 第i维特征的梯度值（libsvm格式数据，x<u>i多为1.）\
\quad \qquad\qquad \sigma</u>i = \frac{1}{\alpha} \left(\sqrt{n<u>i + g</u>i<sup>2}</sup> - \sqrt{n<u>i} \right) \qquad // n</u>i表示第i维梯度（前t-1次）的平方累加和 \
\quad \qquad\qquad z<u>i \leftarrow z</u>{i-1} + g<u>i - \sigma</u>i w<u>{t,i} \qquad // 更新\text{FTRL}目标函数的梯度公式  \
\quad \qquad\qquad n</u>i \leftarrow n<u>i + g</u>i<sup>2</sup>  \qquad // 更新第i维梯度平方累加和值。\
}
\)</p>

<p>FTRL算法添加了per-coordinate学习率，并且支持L2正则项。</p>

<ul>
<li><p>per-coordinate</p>

<p>意思是说FTRL学习过程是对参数向量\(\mathbf{w}\)每一维分开训练更新的，每一维使用不同的学习率。与\(n\)个特征维度使用统一的学习率相比，此种方法考虑到了训练样本本身在不同特征维度上分布不均匀的特点。</p>

<blockquote>
<p>如果包含\(w\)某一个维度特征的训练样本很少，每一个样本都很珍贵，那么该特征维度对应的训练速率可以独自保持比较大的值，每来一个包含该特征的样本，就可以在该样本的梯度上前进一大步，而不需要与其他特征维度的前进步调强行保持一致。</p>
</blockquote></li>
</ul></li>
</ul>

<h5 id="toc_7">FTRL tricks</h5>

<ul>
<li><p>训练数据采样</p>

<p>点击预估中正负样本比值悬殊很大，通过subsampling可以大大减小训练数据集的大小。</p>

<p>subsampling策略：正样本全部采，负样本使用一个比例\(r\)采样。</p>

<p>如果直接使用采样后的数据训练模型，预测时会导致比较大的bias. 解决方案：</p>

<p>模型训练时，对负样本乘以一个权重，即权重直接乘到损失项上面（loss），这样算梯度时，也就带着权重项。</p>

<p>$$
w_i = 
\left {
\begin{array}{ll}
1 &amp; \text{event i is in clicked query} \
\frac{1}{r} &amp; \text{event i is in a query with no clicks.}
\end{array}
\right.
$$</p>

<p><strong>先采样减少负样本数目，在训练的时候再用权重弥补负样本，非常不错的想法。</strong></p></li>
</ul>

<h4 id="toc_8">4.4. DLMC-Core与Rabit基础库功能</h4>

<p>Rabit是一个用于机器之间通信操作的基础库，是实现了MPI程序中的Allreduce和broadcast操作，并提供了可容错的功能。在ADMM分布式学习过程中，主要也是利用Allreduce和Broadcast操作，用于局部参数累加、将updated全局参数 广播至通信域中的各个worker节点。</p>

<div><pre class="line-numbers"><code class="language-none">rabit::op::Max;
rabit::op::Min;
rabit::op::Sum;
rabit::op::BitOR;</code></pre></div>

<p>在MPI中，通信子（communicator）指的是一组可以互相发送消息的进程集合。MPI_Init的其中一个目的，是在用户启动程序时，定义由用户启动的所有进程所组成的通信子。这个通信子称为<code>MPI_COMM_WORLD</code>。</p>

<p>DMLC-Core库主要提供了分布式计算的基础功能，比如序列化接口（IO），定义数据块格式，logging和线程安全的功能。</p>

<h4 id="toc_9">4.5. 调参经验</h4>

<p>ADMM大规模机器学习的调参主要是从3个方面：</p>

<ol>
<li><p>特征方面</p>

<p>LR模型用得到的特征还是“人工特征工程”的做法，通过配置脚本进行特征组合，特征ID化等、特征hash。特征hash的维度需要控制，根据<strong>碰撞率 &lt; 千分之一</strong>的原则，选择dim=300w+1.</p></li>
<li><p>数据方面</p>

<p>训练数据在分布式环境下的节点加载，一个广告位的预估模型训练只在一个节点上进行，有些广告位数据量很大，内存放不下，这个时间需要对训练进行分块，分批读入。需要确定数据切块的个数。</p></li>
<li><p>模型参数和训练</p>

<p>训练过程的迭代次数，FTRL中正则化项系数\(\lambda<u>1, \lambda</u>2, \rho\)等。</p>

<p>迭代次数根据训练时间和收敛情况（auc和logloss指标），选取10. 训练时间：1h左右。</p>

<p>参数根据是否overfitting情况，来调整。结论：\(\lambda<u>2 = 200, \lambda</u>1 = 1, \rho=1 \text{ (step size)}\)</p></li>
</ol>

<h4 id="toc_10">4.6. 指标</h4>

<ul>
<li>offline：auc + logloss</li>
<li>online：流量切分abtest实验，线上平均点击率，通过dashboard观察；</li>
</ul>

<h4 id="toc_11">4.7. ADMM模型线上计算</h4>

<p>线上计算过程：模型解析成字典树，对应叶子节点就是特征值的权重。线上计算ctr的过程，就转化为根据当前cookie对应的特征取值遍历字典树的过程。将得到的叶子节点累加，就得到了ctr结果。</p>

<ul>
<li><p><strong>字典树</strong>：离线模型从redis中读取，线上加载并组织成字典树</p>

<p>字典树，又称单词查找树，是一种hash树的变种。 字典树保存一些字符串-&gt;值的对应关系。他的最大优点是：<strong>利用字符串的公共前缀来节约存储空间，能最大限度地减少无谓的字符串比较，查询效果比hash表高。</strong></p>

<p>Trie的核心思想是空间换时间。利用字符串的公共前缀来降低查询时间的开销以达到提高效率的目的。</p>

<div><pre class="line-numbers"><code class="language-none"> {
&quot;list&quot;: [
  {
    &quot;fid&quot;: &quot;0&quot;, 
    &quot;key&quot;: &quot;P_N_T_1_20631_5d3eb4db5df43584a3c5cb5d3192493c&quot;, 
    &quot;value&quot;: -0.0051592299999999999
  }, 
  {
    &quot;fid&quot;: &quot;0&quot;, 
    &quot;key&quot;: &quot;P_N_T_1_20323_a0971a5a658b38489a90e9a28434bcdf&quot;, 
    &quot;value&quot;: 0.0065683900000000003
  }, 
  {
    &quot;fid&quot;: &quot;0&quot;, 
    &quot;key&quot;: &quot;P_N_T_1_20426_c14e4136cc5a313f8589c9fa339dc1b8&quot;, 
    &quot;value&quot;: 0.054301799999999997
  }, 
&quot;type&quot;: &quot;ps_cmi_ad&quot;
}
```</code></pre></div></li>
<li><p>线上模型的计算流程</p>

<ul>
<li>redis查询，得到候选商品信息＋用户属性信息</li>
<li>根据特征遍历字典树模型，得到的叶子节点（对应特征value）值进行累加，得到的值为ctr值；</li>
</ul>

<p>这样会得到k个商品对应的ctr值：</p>

<div><pre class="line-numbers"><code class="language-none">{
    &quot;cookie&quot;:&quot;cookie1&quot;,
    &quot;ctr&quot;: [
        &quot;uuid_1&quot;:&quot;ctr_1&quot;,
        &quot;uuid_2&quot;:&quot;ctr_2&quot;,
        ...,
        &quot;uuid_k&quot;:&quot;ctr_k&quot;
    ]
}</code></pre></div>

<ul>
<li>按照ctr值（或结合其它因素）排序，返回topK商品。<br></li>
</ul></li>
</ul>



<script type="text/javascript">
var _self="undefined"!=typeof window?window:"undefined"!=typeof WorkerGlobalScope&&self instanceof WorkerGlobalScope?self:{},Prism=function(){var e=/\blang(?:uage)?-(\w+)\b/i,t=0,n=_self.Prism={util:{encode:function(e){return e instanceof a?new a(e.type,n.util.encode(e.content),e.alias):"Array"===n.util.type(e)?e.map(n.util.encode):e.replace(/&/g,"&amp;").replace(/</g,"&lt;").replace(/\u00a0/g," ")},type:function(e){return Object.prototype.toString.call(e).match(/\[object (\w+)\]/)[1]},objId:function(e){return e.__id||Object.defineProperty(e,"__id",{value:++t}),e.__id},clone:function(e){var t=n.util.type(e);switch(t){case"Object":var a={};for(var r in e)e.hasOwnProperty(r)&&(a[r]=n.util.clone(e[r]));return a;case"Array":return e.map&&e.map(function(e){return n.util.clone(e)})}return e}},languages:{extend:function(e,t){var a=n.util.clone(n.languages[e]);for(var r in t)a[r]=t[r];return a},insertBefore:function(e,t,a,r){r=r||n.languages;var l=r[e];if(2==arguments.length){a=arguments[1];for(var i in a)a.hasOwnProperty(i)&&(l[i]=a[i]);return l}var o={};for(var s in l)if(l.hasOwnProperty(s)){if(s==t)for(var i in a)a.hasOwnProperty(i)&&(o[i]=a[i]);o[s]=l[s]}return n.languages.DFS(n.languages,function(t,n){n===r[e]&&t!=e&&(this[t]=o)}),r[e]=o},DFS:function(e,t,a,r){r=r||{};for(var l in e)e.hasOwnProperty(l)&&(t.call(e,l,e[l],a||l),"Object"!==n.util.type(e[l])||r[n.util.objId(e[l])]?"Array"!==n.util.type(e[l])||r[n.util.objId(e[l])]||(r[n.util.objId(e[l])]=!0,n.languages.DFS(e[l],t,l,r)):(r[n.util.objId(e[l])]=!0,n.languages.DFS(e[l],t,null,r)))}},plugins:{},highlightAll:function(e,t){var a={callback:t,selector:'code[class*="language-"], [class*="language-"] code, code[class*="lang-"], [class*="lang-"] code'};n.hooks.run("before-highlightall",a);for(var r,l=a.elements||document.querySelectorAll(a.selector),i=0;r=l[i++];)n.highlightElement(r,e===!0,a.callback)},highlightElement:function(t,a,r){for(var l,i,o=t;o&&!e.test(o.className);)o=o.parentNode;o&&(l=(o.className.match(e)||[,""])[1],i=n.languages[l]),t.className=t.className.replace(e,"").replace(/\s+/g," ")+" language-"+l,o=t.parentNode,/pre/i.test(o.nodeName)&&(o.className=o.className.replace(e,"").replace(/\s+/g," ")+" language-"+l);var s=t.textContent,u={element:t,language:l,grammar:i,code:s};if(!s||!i)return n.hooks.run("complete",u),void 0;if(n.hooks.run("before-highlight",u),a&&_self.Worker){var c=new Worker(n.filename);c.onmessage=function(e){u.highlightedCode=e.data,n.hooks.run("before-insert",u),u.element.innerHTML=u.highlightedCode,r&&r.call(u.element),n.hooks.run("after-highlight",u),n.hooks.run("complete",u)},c.postMessage(JSON.stringify({language:u.language,code:u.code,immediateClose:!0}))}else u.highlightedCode=n.highlight(u.code,u.grammar,u.language),n.hooks.run("before-insert",u),u.element.innerHTML=u.highlightedCode,r&&r.call(t),n.hooks.run("after-highlight",u),n.hooks.run("complete",u)},highlight:function(e,t,r){var l=n.tokenize(e,t);return a.stringify(n.util.encode(l),r)},tokenize:function(e,t){var a=n.Token,r=[e],l=t.rest;if(l){for(var i in l)t[i]=l[i];delete t.rest}e:for(var i in t)if(t.hasOwnProperty(i)&&t[i]){var o=t[i];o="Array"===n.util.type(o)?o:[o];for(var s=0;s<o.length;++s){var u=o[s],c=u.inside,g=!!u.lookbehind,h=!!u.greedy,f=0,d=u.alias;u=u.pattern||u;for(var p=0;p<r.length;p++){var m=r[p];if(r.length>e.length)break e;if(!(m instanceof a)){u.lastIndex=0;var y=u.exec(m),v=1;if(!y&&h&&p!=r.length-1){var b=r[p+1].matchedStr||r[p+1],k=m+b;if(p<r.length-2&&(k+=r[p+2].matchedStr||r[p+2]),u.lastIndex=0,y=u.exec(k),!y)continue;var w=y.index+(g?y[1].length:0);if(w>=m.length)continue;var _=y.index+y[0].length,P=m.length+b.length;if(v=3,P>=_){if(r[p+1].greedy)continue;v=2,k=k.slice(0,P)}m=k}if(y){g&&(f=y[1].length);var w=y.index+f,y=y[0].slice(f),_=w+y.length,S=m.slice(0,w),O=m.slice(_),j=[p,v];S&&j.push(S);var A=new a(i,c?n.tokenize(y,c):y,d,y,h);j.push(A),O&&j.push(O),Array.prototype.splice.apply(r,j)}}}}}return r},hooks:{all:{},add:function(e,t){var a=n.hooks.all;a[e]=a[e]||[],a[e].push(t)},run:function(e,t){var a=n.hooks.all[e];if(a&&a.length)for(var r,l=0;r=a[l++];)r(t)}}},a=n.Token=function(e,t,n,a,r){this.type=e,this.content=t,this.alias=n,this.matchedStr=a||null,this.greedy=!!r};if(a.stringify=function(e,t,r){if("string"==typeof e)return e;if("Array"===n.util.type(e))return e.map(function(n){return a.stringify(n,t,e)}).join("");var l={type:e.type,content:a.stringify(e.content,t,r),tag:"span",classes:["token",e.type],attributes:{},language:t,parent:r};if("comment"==l.type&&(l.attributes.spellcheck="true"),e.alias){var i="Array"===n.util.type(e.alias)?e.alias:[e.alias];Array.prototype.push.apply(l.classes,i)}n.hooks.run("wrap",l);var o="";for(var s in l.attributes)o+=(o?" ":"")+s+'="'+(l.attributes[s]||"")+'"';return"<"+l.tag+' class="'+l.classes.join(" ")+'" '+o+">"+l.content+"</"+l.tag+">"},!_self.document)return _self.addEventListener?(_self.addEventListener("message",function(e){var t=JSON.parse(e.data),a=t.language,r=t.code,l=t.immediateClose;_self.postMessage(n.highlight(r,n.languages[a],a)),l&&_self.close()},!1),_self.Prism):_self.Prism;var r=document.currentScript||[].slice.call(document.getElementsByTagName("script")).pop();return r&&(n.filename=r.src,document.addEventListener&&!r.hasAttribute("data-manual")&&document.addEventListener("DOMContentLoaded",n.highlightAll)),_self.Prism}();"undefined"!=typeof module&&module.exports&&(module.exports=Prism),"undefined"!=typeof global&&(global.Prism=Prism);
</script>

<script type="text/javascript">
!function(){"undefined"!=typeof self&&self.Prism&&self.document&&Prism.hooks.add("complete",function(e){if(e.code){var t=e.element.parentNode,s=/\s*\bline-numbers\b\s*/;if(t&&/pre/i.test(t.nodeName)&&(s.test(t.className)||s.test(e.element.className))&&!e.element.querySelector(".line-numbers-rows")){s.test(e.element.className)&&(e.element.className=e.element.className.replace(s,"")),s.test(t.className)||(t.className+=" line-numbers");var n,a=e.code.match(/\n(?!$)/g),l=a?a.length+1:1,m=new Array(l+1);m=m.join("<span></span>"),n=document.createElement("span"),n.className="line-numbers-rows",n.innerHTML=m,t.hasAttribute("data-start")&&(t.style.counterReset="linenumber "+(parseInt(t.getAttribute("data-start"),10)-1)),e.element.appendChild(n)}}})}();
</script>


</body>

</html>
